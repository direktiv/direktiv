# -- Container registry from which to pull direktiv.
registry: "docker.io"

# -- Container pull policy.
pullPolicy: Always

# -- Container registry secrets.
imagePullSecrets: []

# -- image for main direktiv binary
image: "direktiv/direktiv"

# -- image tag for main direktiv binary pod
tag: ""

# -- enabled api key for API authentication with the `direktiv-token` header
apikey: none

# -- max request timeouts in seconds. Used in Knative and the ingress controller if enabled.
requestTimeout: 7200

nodeSelector: {}
tolerations: []
affinity: {}

flow:
  # -- Output debug-level logs.
  debug: false
  # -- Set to define an encryption key to be used for secrets. If set to empty, one will be generated on install.
  encryptionKey:
  # -- number of flow replicas
  replicas: 1
  # -- extra environment variables in flow pod
  extraVariables:
    []
    # - name:
    #   value:
  # -- extra container in flow pod
  extraContainers: []
  # -- extra volume mounts in flow pod
  extraVolumeMounts:
    # - name: service-template
    #   mountPath: /etc/config
  # -- extra volumes in flow pod
  extraVolumes:
    # - name: service-template
    #   configMap:
    #     name: service-template
  # -- affinity for flow pods
  affinity:
    {}
    # podAntiAffinity:
    #   requiredDuringSchedulingIgnoredDuringExecution:
    #   - labelSelector:
    #       matchExpressions:
    #       - key: app.kubernetes.io/name
    #         operator: In
    #         values:
    #         - direktiv
    #     topologyKey: kubernetes.io/hostname
  containers:
    secrets:
      resources:
        requests:
          memory: "128Mi"
        limits:
          memory: "512Mi"

  # -- Knative max scale
  max_scale: 5
  sidecar:

database:
  # -- database host
  host: "postgres-postgresql-ha-pgpool.postgres"
  # -- database port
  port: 5432
  # -- database user
  user: "direktiv"
  # -- database password
  password: "direktivdirektiv"
  # -- database name, has to be created before installation
  name: "direktiv"
  # -- sslmode for database
  sslmode: require
  # -- additional connection attributes, e.g. target_session_attrs
  additional: ""

# Added this to connect to tracing.direktiv.io
opentelemetry:
  enabled: false
  image: otel/opentelemetry-collector-dev:latest
  agentconfig: |
    receivers:
      otlp:
        protocols:
          grpc:
          http:
    exporters:
      otlp:
        endpoint: "data-prepper.default.svc:21890" # Data Prepper's gRPC endpoint
        insecure: true
        sending_queue:
          num_consumers: 4
          queue_size: 100
        retry_on_failure:
          enabled: true
      logging:
        loglevel: debug
    processors:
      batch:
      memory_limiter:
        # Memory management
        ballast_size_mib: 165
        limit_mib: 400
        spike_limit_mib: 100
        check_interval: 5s
    extensions:
      zpages: {}
    service:
      extensions: [zpages]
      pipelines:
        traces:
          receivers: [otlp]
          processors: [memory_limiter, batch]
          exporters: [logging, otlp]

ingress:
  # --
  enabled: true
  # -- Host for external services, only required for TLS
  host:
  # -- TLS secret
  certificate:
  # -- Ingress class
  class: "nginx"
  # -- Additional Annotations
  additionalAnnotations: {}
  # -- Additional Labels
  additionalLabels: {}

# -- nginx ingress controller configuration
ingress-nginx:
  install: true
  controller:
    podAnnotations:
      linkerd.io/inject: disabled
    config:
      proxy-buffer-size: "16k"
    replicaCount: 1
    admissionWebhooks:
      patch:
        podAnnotations:
          linkerd.io/inject: disabled

fluent-bit:
  install: true
  envFrom:
    - secretRef:
        name: direktiv-fluentbit
  config:
    inputs: |
      [INPUT]
          Name                    tail
          Path                    /var/log/containers/*flow*.log,/var/log/containers/*direktiv-sidecar*.log
          Mem_Buf_Limit           5MB
          Skip_Long_Lines         Off
          Tag                     input
          multiline.parser        cri, docker
          Refresh_Interval        1
          Buffer_Max_Size         64k
    outputs: |
      [OUTPUT]
          Name                    http
          Match                   *
          Host                    direktiv-data-prepper.default.svc
          Port                    2021
          URI                     /v1/logs
          Format                  json
          Retry_Limit             False
          tls                     Off
    filters: |
      [FILTER]
          Name                    rewrite_tag
          Match                   input
          Rule                    $log ^.*"track":"([^"]*).*$ flow.$1 true
      [FILTER]
          Name                    parser
          Match                   *
          Parser                  json
          Key_Name                log
          Reserve_Data            on

# -- service account for components. If preconfigured serviceaccounts are used the name ise the base
# and two additional service accounts are needed, e.g. service account name is myaccount then another two
# acounts are needed: myaccount-functions and myaccount-functions-pod
serviceAccount:
  annotations: {}
  name: ""
  create: true
  # example to annotate for GCP database access
  #   annotations:
  #      iam.gke.io/gcp-service-account: IAM_USER@GCP_PROJECT.iam.gserviceaccount.com

# -- http proxy settings
http_proxy: ""
# -- https proxy settings
https_proxy: ""
# -- no proxy proxy settings
no_proxy: ""

functions:
  # -- knative service limits
  limits:
    memory:
      small: 512
      medium: 1024
      large: 2048
    cpu:
      small: 250m
      medium: 500m
      large: 1
    disk:
      small: 256
      medium: 1024
      large: 4096

  # namespace to run functions in
  namespace: direktiv-services-direktiv
  ingressClass: contour.ingress.networking.knative.dev

  # -- number of controller replicas
  replicas: 1

  # -- Egress/Ingress network limit for functions if supported by network
  netShape:

  # -- Cleaning up tasks, Kubernetes < 1.20 does not clean finished tasks
  podCleaner: true # deprecated

  # -- runtime to use, e.g. gvisor on GCP
  runtime: "default"

  affinity: {}

  # -- extra containers for function controller, e.g. database containers for google cloud or logging
  extraContainersPod: []

  # -- extra volumes for tasks and knative pods
  extraVolumes: []
  #   - configMap:
  #   name: otel-agent-conf
  #   items:
  #     - key: otel-agent-config
  #       path: otel-agent-config.yaml
  # name: otel-agent-config-vol

  # -- extra containers for tasks and knative pods
  extraContainers:
    []
    # - name: cloud-sql-proxy
    #   image: gcr.io/cloudsql-docker/gce-proxy:1.17
    #   command:
    #     - "/cloud_sql_proxy"
    #     - "-instances=mygcpdb=tcp:5432"
    #     - "-ip_address_types=PRIVATE"
    #   securityContext:
    #     runAsNonRoot: true
    #   resources:
    #     requests:
    #       memory: "2Gi"
    #       cpu:    "1"

nats:
  install: false
  config:
    cluster:
      enabled: true
      port: 6222
      replicas: 3
    tls:
      enabled: false
      secretName:
      dir: /etc/nats-certs/cluster
      cert: tls.crt
      key: tls.key
    routeURLs:
      user: direktiv
      password: direktiv
      useFQDN: false
      k8sClusterDomain: cluster.local
    nats:
      port: 4222
      tls:
        enabled: false

opensearch:
  install: false
  clusterName: "direktiv-opensearch-cluster"
  persistence:
    enabled: true
    accessModes:
      - ReadWriteOnce
    size: 8Gi
    storageClassName: "local-path"
  services:
    enviroment:
  extraEnvs:
    - name: OPENSEARCH_INITIAL_ADMIN_PASSWORD
      value: direktivTr0&3
    - name: "ES_JAVA_OPTS"
      value: "Xms4g -Xmx4g"
  plugins:
    security:
      ssl_cert_reload_enabled: true
      ssl:
        transport:
          pemcert_filepath: esnode.pem
          pemkey_filepath: esnode-key.pem
          pemtrustedcas_filepath: root-ca.pem
          enforce_hostname_verification: false
        http:
          enabled: false
      allow_unsafe_democertificates: true

  protocol: https
  httpPort: 9200

dataprepper:
  enabled: true
  ports:
    - name: http-source
      port: 2021
    - name: otel-traces
      port: 21890
    - name: otel-metrics
      port: 21891
    - name: otel-logs
      port: 21892
  pipelineConfig:
    enabled: true
    config:
      otel-logs-pipeline:
        source:
          otel-logs:
            type: "OTLP"
            http:
              port: 2021
        processor:
          - add_entry_time: {}
        sink:
          - opensearch:
              hosts: ["http://opensearch-cluster-master.default.svc:9200"]
              insecure: true
              index: "direktiv-logs"
      traces-pipeline:
        source:
          otel-traces:
            type: "OTLP"
            grpc:
              port: 21890
        sink:
          - opensearch:
              hosts: ["http://opensearch-cluster-master.default.svc:9200"]
              insecure: true
              index_type: "trace-analytics-service-map"
              index: "direktiv-otel-v1-apm-span"
